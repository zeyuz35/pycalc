{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.13.2 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors tutorial\n",
    "\n",
    "# preliminary\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing tensors\n",
    "# this is manually, and datatype is automatically inferred\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, we can also use numpy arrays (more common)\n",
    "np_array = np.array(data)\n",
    "# convert from tensor back to numpy array\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ones Tensor: \n tensor([[1, 1],\n        [1, 1]]) \n\nRandom Tensors: \n tensor([[0.4405, 0.5021],\n        [0.1997, 0.9122]]) \n\n"
     ]
    }
   ],
   "source": [
    "# can also concatenate from another tensor\n",
    "# this retains the properties of the x_data\n",
    "x_ones = torch.ones_like(x_data)\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "# overrides the datatype of x_data, may be useful in some situations\n",
    "# torch.rand_like generates these from a uniform 0,1 dist\n",
    "# rand_like generatesa andom tensor te same size as another tensor, i.e. convenience function\n",
    "x_rand = torch.rand_like(x_data, dtype = torch.float)\n",
    "print(f\"Random Tensors: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Attributes of a tensor\n",
    "# rand is the BASE function that requires you to specify the dimensions manually\n",
    "tensor = torch.rand(3, 4)\n",
    "# three main attributes we care about\n",
    "tensor.shape\n",
    "tensor.dtype\n",
    "tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operations on Tensors\n",
    "# By defualt, all tensor operators are on CPU\n",
    "# and you need to move tensors to GPU for speedup manually\n",
    "\n",
    "# These are called \"accerlerators\"\n",
    "if torch.accelerator.is_available():\n",
    "    tensor = tensor.to(torch.accelerator.current_accelerator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 0,  4,  8, 12])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Tensor API is very similar to NumPy API\n",
    "# recall that Python has 0 based indexing\n",
    "tensor = torch.from_numpy(np.array(range(0, 16)).reshape(4, 4))\n",
    "# First row\n",
    "tensor[0, :]\n",
    "# First Columns\n",
    "tensor[:, 0]\n",
    "# Last column (unique Python based indexing)\n",
    "# tensor[:, -(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Joining Tensors\n",
    "# rbind\n",
    "torch.cat([tensor, tensor], dim = 0)\n",
    "# cbind\n",
    "torch.cat([tensor, tensor], dim = 1)\n",
    "\n",
    "# stack is somewhat different, essentially stacks the arrays to yield a higher dimensional object\n",
    "# e.g. 2d -> 3d\n",
    "# the dim arument in this case corresponds to where you want the dimension to increase/stacked\n",
    "three_d = torch.stack([tensor, tensor], dim = 2)\n",
    "three_d.shape\n",
    "# torch.stack([three_d, three_d], dim = 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 14,  38,  62,  86],\n        [ 38, 126, 214, 302],\n        [ 62, 214, 366, 518],\n        [ 86, 302, 518, 734]])\ntensor([[ 14,  38,  62,  86],\n        [ 38, 126, 214, 302],\n        [ 62, 214, 366, 518],\n        [ 86, 302, 518, 734]])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.,   4.,   9.],\n",
       "        [ 16.,  25.,  36.,  49.],\n",
       "        [ 64.,  81., 100., 121.],\n",
       "        [144., 169., 196., 225.]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Arithmetic Operators\n",
    "# @ is used for  MATRIX mutiplication\n",
    "# .T is used  Transpose a tensor\n",
    "y1 = tensor @ tensor.T\n",
    "print(y1)\n",
    "\n",
    "# alternatively, using the clunky OOP approach\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "print(y2)\n",
    "\n",
    "# Elementwise multiplication\n",
    "# uses asterisk * instead (similar to R)\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "# rand_like only works with floats, so dtype conversion is necessary\n",
    "z3 = torch.rand_like(tensor, dtype = torch.float)\n",
    "\n",
    "torch.mul(tensor, tensor, out = z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "120 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# Converting this back to a numebr can be done via item()\n",
    "# sum of a tensor\n",
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11],\n        [12, 13, 14, 15]])\ntensor([[ 5,  6,  7,  8],\n        [ 9, 10, 11, 12],\n        [13, 14, 15, 16],\n        [17, 18, 19, 20]])\ntensor([[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11],\n        [12, 13, 14, 15]])\n"
     ]
    }
   ],
   "source": [
    "# In place operators\n",
    "# These directly manipulate the object and store them in place\n",
    "# These are against the principles of Functional Programming\n",
    "# Denoted with a _ suffix\n",
    "# e.g.\n",
    "# x.copy_(y), x.t_() will all change x\n",
    "print(tensor)\n",
    "tensor.add_(5)\n",
    "print(tensor)\n",
    "tensor.subtract_(5)\n",
    "print(tensor)\n",
    "\n",
    "# These are mainly useful for saving memory\n",
    "# However, they erase history, which can fuck up derivatives later on\n",
    "# Try to avoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\nn: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Bridging this with NumPy\n",
    "# print f is for printing formatted string literals\n",
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "# convert to numpy\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}